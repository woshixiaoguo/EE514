{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4b5617-aa46-4385-9964-a3bac5ae5a15",
   "metadata": {},
   "source": [
    "## Planet four image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746335e6-87ca-4786-ada5-a042ad526425",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import sklearn.metrics as metrics\n",
    "import tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets.folder import pil_loader\n",
    "from pathlib import Path\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c002513-1fe7-4786-88cd-07d35fc0b430",
   "metadata": {},
   "source": [
    "Change the device to \"cpu\" if you want to train on a CPU instead of a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad120f2-9393-4c57-87a7-8197e9a1245d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837c532e-5cfc-4216-a321-419968407f37",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Here we define a custom Dataset object for the Planet Four data. You can read more about this in the PyTorch documentation: https://pytorch.org/tutorials/beginner/basics/data_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9356db-6837-4444-bdab-a4aea56007a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "class PlanetFourDataset(object):\n",
    "    def __init__(self, split='train', transform=None, loader=pil_loader):\n",
    "        super().__init__()\n",
    "        self.split = split\n",
    "        self.base_dir = Path('data/planetfour')  # 数据集路径\n",
    "        self.image_dir = self.base_dir / split\n",
    "        self.labels_file = self.base_dir / (split + '.csv')\n",
    "        self.labels_df = pd.read_csv(self.labels_file)\n",
    "        self.transform = transform\n",
    "        self.loader = loader\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        row = self.labels_df.iloc[index]\n",
    "        filename = self.image_dir / (row.tile_id + '.jpg')\n",
    "        fans = int(row.fans)\n",
    "        blotches = int(row.blotches)\n",
    "        image = self.loader(str(filename))\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor([fans, blotches], dtype=torch.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6ef1da-a034-4d88-bbab-64dbce05da6a",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "It is standard practice in deep learning to augment the training examples to prevent the network from overfitting. Here I use some standard augmentations such as randomly mirroring the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198239e2-84ff-4e33-a1dd-7b9a18f68d49",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))                  \n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)) \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7a5b9c-33a6-4bfc-a699-05f3415de676",
   "metadata": {},
   "source": [
    "## Data loaders\n",
    "\n",
    "In PyTorch, the data loaders take care of spinning up threads to load batches of data into memory from the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2fb4c-e711-49a0-9a21-fb8249972ffc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "train_set = PlanetFourDataset('train', transform=train_transform)\n",
    "valid_set = PlanetFourDataset('valid', transform=train_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbd1e9b-801b-4da5-975a-6c061b16b005",
   "metadata": {},
   "source": [
    "## Load a pretrained model\n",
    "\n",
    "Here we'll use ResNet50 model that has been pretrained on ImageNet and replace the final layer with a new one suited to our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e84455f-5c9c-4ccd-a107-bf19e6fec48e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(2048, 2)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3d8cc2-2be4-48e7-aa2e-f35d7a835796",
   "metadata": {},
   "source": [
    "## Loss\n",
    "\n",
    "Images can contain fans, blotches, both, or neither. You could treat this as a four class softmax problem, or two binary classification problems. Here I take the latter approach and use a binary cross entropy loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6729d82b-3a4c-4036-a95d-70695d528bb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426c8e89-d806-420f-a76c-ab10d1d4e406",
   "metadata": {},
   "source": [
    "## Optimizer\n",
    "\n",
    "Stochastic gradient descent with momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac8696-3a99-40c1-ab9f-d95971bd1f40",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c709bf-c5cb-433b-b8af-678759182eef",
   "metadata": {},
   "source": [
    "## Training and validation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26eb5f0c-7b1d-49f1-8682-097d0ae64e54",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "avg_train_losses = []\n",
    "avg_valid_losses = []\n",
    "valid_accuracies = []\n",
    "\n",
    "\n",
    "def train_for_epoch(optimizer):\n",
    "    model.train()\n",
    "\n",
    "    train_losses = []\n",
    "\n",
    "    for batch, target in tqdm.tqdm(train_loader):\n",
    "\n",
    "        # data to GPU\n",
    "        batch = batch.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # reset optimizer\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward pass\n",
    "        predictions = model(batch)\n",
    "        #breakpoint()\n",
    "\n",
    "        # calculate loss\n",
    "        loss = criterion(predictions, target)\n",
    "\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # parameter update\n",
    "        optimizer.step()\n",
    "\n",
    "        # track loss\n",
    "        train_losses.append(float(loss.item()))\n",
    "\n",
    "    train_losses = np.array(train_losses)\n",
    "    return train_losses\n",
    "\n",
    "\n",
    "def validate():\n",
    "    model.eval()\n",
    "\n",
    "    valid_losses = []\n",
    "    y_true, y_prob = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, target in valid_loader:\n",
    "\n",
    "            # move data to the device\n",
    "            batch = batch.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # make predictions\n",
    "            predictions = model(batch)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = criterion(predictions, target)\n",
    "            \n",
    "            # logits -> probabilities\n",
    "            torch.sigmoid_(predictions)\n",
    "\n",
    "            # track losses and predictions\n",
    "            valid_losses.append(float(loss.item()))\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_prob.extend(predictions.cpu().numpy())\n",
    "            \n",
    "    y_true = np.array(y_true)\n",
    "    y_prob = np.array(y_prob)\n",
    "    y_pred = y_prob > 0.5\n",
    "    valid_losses = np.array(valid_losses)\n",
    "\n",
    "    # calculate validation accuracy from y_true and y_pred\n",
    "    fan_accuracy = metrics.accuracy_score(y_true[:,0], y_pred[:,0])\n",
    "    blotch_accuracy = metrics.accuracy_score(y_true[:,1], y_pred[:,1])\n",
    "    exact_accuracy = np.all(y_true == y_pred, axis=1).mean()\n",
    "\n",
    "    # calculate the mean validation loss\n",
    "    valid_loss = valid_losses.mean()\n",
    "\n",
    "    return valid_loss, fan_accuracy, blotch_accuracy, exact_accuracy\n",
    "\n",
    "\n",
    "def train(epochs, first_epoch=1):\n",
    "    for epoch in range(first_epoch, epochs+first_epoch):\n",
    "\n",
    "        # train\n",
    "        train_loss = train_for_epoch(optimizer)\n",
    "\n",
    "        # validation\n",
    "        valid_loss, fan_accuracy, blotch_accuracy, both_accuracy = validate()\n",
    "        print(f'[{epoch:02d}] train loss: {train_loss.mean():0.04f}  '\n",
    "              f'valid loss: {valid_loss:0.04f}  ',\n",
    "              f'fan acc: {fan_accuracy:0.04f}  ',\n",
    "              f'blotch acc: {blotch_accuracy:0.04f}  ',\n",
    "              f'both acc: {both_accuracy:0.04f}'\n",
    "        )\n",
    "        \n",
    "        # update learning curves\n",
    "        avg_train_losses.append(train_loss.mean())\n",
    "        avg_valid_losses.append(valid_loss)\n",
    "        valid_accuracies.append((fan_accuracy, blotch_accuracy, both_accuracy))\n",
    "        \n",
    "        # save checkpoint\n",
    "        #torch.save(model, f'checkpoints/baseline_{epoch:03d}.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b750e3a-4357-420e-b89e-aa1afbd35e2d",
   "metadata": {},
   "source": [
    "## Constant classifier accuracy\n",
    "\n",
    "Evaluate how accurate would a $f(x) = \\text{\"most common class\"}$ classifier be? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66147496-e69a-4391-89bf-d24d7c797371",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def constant_clf_accuracy():\n",
    "    y_true, y_pred = [], []\n",
    "    with torch.no_grad():\n",
    "        for _, target in valid_loader:\n",
    "            y_true.extend(target.cpu().numpy())\n",
    "            y_pred.extend(np.ones((target.shape[0], 2), dtype=np.float32))\n",
    "            \n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "        \n",
    "    # calculate validation accuracy from y_true and y_pred\n",
    "    f = metrics.accuracy_score(y_true[:,0], y_pred[:,0])\n",
    "    b = metrics.accuracy_score(y_true[:,1], y_pred[:,1])\n",
    "    t = np.all(y_true == y_pred, axis=1).mean()\n",
    "    print(f'fan: {f}  blotch: {b}  both: {t}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0148aec5-f941-4499-b107-65bff2ca87c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "constant_clf_accuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c698dd8-6e41-4bba-9f77-82ed162a647f",
   "metadata": {},
   "source": [
    "## Train the model\n",
    "Call the ``train(n)`` function to train for ``n`` epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1baa5b9-b8d7-41c2-8e93-061af75185c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python ('mlsd_pytorch')' requires ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n mlsd_pytorch ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ('mlsd_pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": ""
  },
  "vscode": {
   "interpreter": {
    "hash": "25a19fbe0a9132dfb9279d48d161753c6352f8f9478c2e74383d340069b907c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
